{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "testing-huggingface",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "70bb7c0669ca4a3699ad36dfdcc10910": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1ba158d2f09a4c54bc647ebe77d27b60",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5ac8ad6eea254d369996622911a6a79e",
              "IPY_MODEL_0aeb387a0f53469c8ff42e57647831d8"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "1ba158d2f09a4c54bc647ebe77d27b60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "5ac8ad6eea254d369996622911a6a79e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_efd6b87b93244d5ca6817ab35c385510",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 6589,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 6589,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e22006901f10483882e1a1f20f645b24"
          },
          "model_module_version": "1.5.0"
        },
        "0aeb387a0f53469c8ff42e57647831d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_01644f724526402c9f139e19b2035073",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 6589/6589 [02:35&lt;00:00, 42.40ba/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7097c890712d418e9dd9c3e33873a2d5"
          },
          "model_module_version": "1.5.0"
        },
        "efd6b87b93244d5ca6817ab35c385510": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "e22006901f10483882e1a1f20f645b24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "01644f724526402c9f139e19b2035073": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "7097c890712d418e9dd9c3e33873a2d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "b3ddde0882d841daa3bfde43ed6e6fc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_09375b2aac814adcbb51589402eb8b68",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cab0cd369bfa4c80b963ebd27d3e4974",
              "IPY_MODEL_db0264404d934633824b5b381b31a5ac"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "09375b2aac814adcbb51589402eb8b68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "cab0cd369bfa4c80b963ebd27d3e4974": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_63276058881e45539d8dcd4ff2e05edd",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1416,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1416,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_03b57581ace346d2bde4378a7c6309ca"
          },
          "model_module_version": "1.5.0"
        },
        "db0264404d934633824b5b381b31a5ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5507016090f64bb99dcbf88e14d71eda",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1416/1416 [00:44&lt;00:00, 31.76ba/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0d6a0b11ec2a4c6d975857678415f505"
          },
          "model_module_version": "1.5.0"
        },
        "63276058881e45539d8dcd4ff2e05edd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "03b57581ace346d2bde4378a7c6309ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "5507016090f64bb99dcbf88e14d71eda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "0d6a0b11ec2a4c6d975857678415f505": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "0ef7f4e43319429d9277d55c83cb084d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ab543b6ef5b34ed4acb85fd25304ed75",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_825d4b325e9b45859e808cd6b14fdd42",
              "IPY_MODEL_dd0bdf658c6d4c0cb0a091129ecbebb0"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "ab543b6ef5b34ed4acb85fd25304ed75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "825d4b325e9b45859e808cd6b14fdd42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f7c296a0b8a84ee3be45c92edb6aad21",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 22,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 22,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e21d97b40ffa43668b9962c5d771debb"
          },
          "model_module_version": "1.5.0"
        },
        "dd0bdf658c6d4c0cb0a091129ecbebb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a4898ec38618401396928eee2c4f9926",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 22/22 [29:59&lt;00:00, 81.81s/ba]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3598a3c015a64c20be134cf4d2e7fbbe"
          },
          "model_module_version": "1.5.0"
        },
        "f7c296a0b8a84ee3be45c92edb6aad21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "e21d97b40ffa43668b9962c5d771debb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "a4898ec38618401396928eee2c4f9926": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "3598a3c015a64c20be134cf4d2e7fbbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tklee-123/AI/blob/main/notebooks/training_vietnews.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6hRf-gcm92k"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgp6VBA8DQ-l",
        "outputId": "b7c65456-47f9-4462-ad97-185dc2e1a94e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Authenticate\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "print('Authenticated')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Authenticated\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gx4Vg4cbEUJ_"
      },
      "source": [
        "OUTPUT_DIR = '/content/training/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVUAENd5DYp6"
      },
      "source": [
        "import random\n",
        "\n",
        "random.seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_GCCIaj7ulj"
      },
      "source": [
        "!wget 'https://github.com/ThanhChinhBK/vietnews/archive/master.zip'\n",
        "!unzip 'master.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzywNFmeKVgx"
      },
      "source": [
        "%%capture\n",
        "\n",
        "# !wget 'https://github.com/CLC-HCMUS/ViMs-Dataset/raw/master/ViMs.zip'\n",
        "# !unzip 'ViMs.zip'\n",
        "\n",
        "# Install the vncorenlp python wrapper\n",
        "!pip install vncorenlp\n",
        "\n",
        "# Download VnCoreNLP-1.1.1.jar & its word segmentation component (i.e. RDRSegmenter)\n",
        "!mkdir -p vncorenlp/models/wordsegmenter\n",
        "!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\n",
        "!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab\n",
        "!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\n",
        "!mv VnCoreNLP-1.1.1.jar vncorenlp/\n",
        "!mv vi-vocab vncorenlp/models/wordsegmenter/\n",
        "!mv wordsegmenter.rdr vncorenlp/models/wordsegmenter/\n",
        "!pip install datasets==1.0.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZYjioRkKviO"
      },
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "import concurrent.futures\n",
        "from datasets import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IteMtlc58-y"
      },
      "source": [
        "## Processing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWuj00alIK5D"
      },
      "source": [
        "from vncorenlp import VnCoreNLP\n",
        "rdrsegmenter = VnCoreNLP(\"./vncorenlp/VnCoreNLP-1.1.1.jar\", annotators=\"wseg\", max_heap_size='-Xmx2g')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVkc5HmK6Bdd"
      },
      "source": [
        "def listPaths(path):\n",
        "  pathfiles = list()\n",
        "  for pathfile in glob.glob(path):\n",
        "    pathfiles.append(pathfile)\n",
        "  return pathfiles\n",
        "\n",
        "train_paths = listPaths('/content/vietnews-master/data/train_tokenized/*')\n",
        "val_paths = listPaths('/content/vietnews-master/data/val_tokenized/*')\n",
        "test_paths = listPaths('/content/vietnews-master/data/test_tokenized/*')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ8pgIYN7zSW"
      },
      "source": [
        "def read_content(pathfile):\n",
        "  \"\"\"\n",
        "  Input: Path of txt file\n",
        "  Output: A dictionary has keys 'original' and 'summary'\n",
        "  \"\"\"\n",
        "  with open(pathfile) as f:\n",
        "    rows  = f.readlines()\n",
        "    original = ' '.join(''.join(rows[4:]).split('\\n'))\n",
        "    summary = ' '.join(rows[2].split('\\n'))\n",
        "\n",
        "  return {'file' : pathfile,\n",
        "            'original': original,\n",
        "            'summary': summary}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_716GF2iDTcD",
        "outputId": "07268442-c69d-4818-a69a-2f9200044eed"
      },
      "source": [
        "read_content(train_paths[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'file': '/content/vietnews-master/data/train_tokenized/033889.txt.seg',\n",
              " 'original': 'Theo RT , liên_quân do Mỹ dẫn_đầu được cho là đã không_kích các vị_trí của quân_đội Syria tại khu_vực Al_Bukamal thuộc tỉnh Deir ez - Zor , phía Đông_Syria . Thông_tin trên được hãng thông_tấn nhà_nước Syria SANA trích_dẫn nguồn tin quân_sự cho_hay . Theo đó , cuộc không_kích nhằm vào một_số vị_trí của quân_đội Syria tại al - Harra , phía Đông nam khu_vực Al_Bukamal . Theo nguồn_tin này , vụ không_kích dẫn đến tổn_thất về nhân_lực của quân_đội Syria , tuy_nhiên con_số thương_vong cụ_thể chưa được công_bố . Vụ không_kích này có_thể do một_số máy_bay_không_người_lái ( UAV ) của Mỹ thực_hiện , đồng_thời vụ không_kích này được cho là nhằm vào một_số vị_trí của lực_lượng Iraq và quân_đội Chính_phủ Syria tại khu_vực giữa Al_Bukamal và Tanf . Tuy_nhiên , hiện Lầu_Năm_Góc phủ_nhận có liên_quan tới vụ_việc . Đây không phải là vụ không kích đầu_tiên nhằm vào lực_lượng quân_đội Syria và các lực_lượng ủng_hộ Chính_phủ Syria tại Deir ez - Zor , nơi Lực_lượng Syria Dân_chủ ( SDF ) do phương Tây hậu_thuẫn đang hoạt_động . Lực_lượng SDF với sự hỗ_trợ của liên_minh chống IS do Mỹ dẫn_đầu bắt_đầu triển_khai chiến_dịch vào ngày 1/5/2018 với mục_tiêu quét sạch những chiến_binh thánh_chiến còn sót lại tại khu_vực biên_giới Syria – Iraq và trung_tâm thung_lũng sông Euphrates . Để giúp lực_lượng đồng_minh giành được vị_trí trên mặt_đất , liên_minh này thực_hiện 225 vụ không_kích với 280 lần đụng_độ chỉ trong tháng 5 . Liên_quân do Mỹ dẫn_đầu đang ủng_hộ các nhóm vũ_trang người Kurds và Arab tại Syria đối_phó với nhóm Nhà_nước Hồi_giáo tự_xưng ( IS ) ở khu_vực Đông_Bắc_Albu_Kamal . Mặc_dù quân_đội Syria cùng với sự hỗ_trợ của các lực_lượng đã kiểm_soát được khu_vực cùng những vùng phụ_cận vào năm_ngoái , nhưng nhóm phiến quân này vẫn thực_hiện các vụ tấn_công trong khu_vực . Xem thêm > > Israel hé lộ tên_lửa có_thể xuyên thủng mọi lá_chắn phòng_không ở Trung_Đông  ',\n",
              " 'summary': 'Lực_lượng liên_quân do Mỹ dẫn_đầu được cho là đã không kích ồ_ạt vào một trong những căn_cứ của quân_đội Syria tại phía Đông quốc_gia Trung_Đông này . '}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wm5kLJD_840E"
      },
      "source": [
        "def get_dataframe(pathfiles):\n",
        "  with concurrent.futures.ProcessPoolExecutor() as executor:\n",
        "    data = executor.map(read_content, pathfiles)\n",
        "\n",
        "  # Make blank dataframe\n",
        "  data_df = list()\n",
        "  for d in data:\n",
        "    data_df.append(d)\n",
        "  data_df = pd.DataFrame(data_df)\n",
        "  data_df.dropna(inplace = True)\n",
        "  data_df = data_df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "  return data_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4c0pl5BAl3f"
      },
      "source": [
        "train_df = get_dataframe(train_paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgMgMnisA0cf"
      },
      "source": [
        "val_df = get_dataframe(val_paths)\n",
        "test_df = get_dataframe(test_paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1F58j028eTV"
      },
      "source": [
        "## **Warm-starting RoBERTaShared for BBC XSum**\n",
        "\n",
        "***Note***: This notebook only uses a few training, validation, and test data samples for demonstration purposes. To fine-tune an encoder-decoder model on the full training data, the user should change the training and data preprocessing parameters accordingly as highlighted by the comments.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FO5ESocXvlK"
      },
      "source": [
        "### **Data Preprocessing**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w67vkz3KP9eZ"
      },
      "source": [
        "%%capture\n",
        "!pip install datasets==1.0.2\n",
        "!pip install transformers\n",
        "\n",
        "import datasets\n",
        "import transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgTiC0rhMb7C"
      },
      "source": [
        "from transformers import RobertaTokenizerFast,AutoTokenizer\n",
        "\n",
        "# phobert = AutoModel.from_pretrained(\"vinai/phobert-base\")\n",
        "\n",
        "# For transformers v4.x+:\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\", use_fast=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U08MrUK9LcUM"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data =  Dataset.from_pandas(train_df)\n",
        "val_data =  Dataset.from_pandas(val_df)\n",
        "test_data =  Dataset.from_pandas(test_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoN2q0hZUbXN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "70bb7c0669ca4a3699ad36dfdcc10910",
            "1ba158d2f09a4c54bc647ebe77d27b60",
            "5ac8ad6eea254d369996622911a6a79e",
            "0aeb387a0f53469c8ff42e57647831d8",
            "efd6b87b93244d5ca6817ab35c385510",
            "e22006901f10483882e1a1f20f645b24",
            "01644f724526402c9f139e19b2035073",
            "7097c890712d418e9dd9c3e33873a2d5",
            "b3ddde0882d841daa3bfde43ed6e6fc9",
            "09375b2aac814adcbb51589402eb8b68",
            "cab0cd369bfa4c80b963ebd27d3e4974",
            "db0264404d934633824b5b381b31a5ac",
            "63276058881e45539d8dcd4ff2e05edd",
            "03b57581ace346d2bde4378a7c6309ca",
            "5507016090f64bb99dcbf88e14d71eda",
            "0d6a0b11ec2a4c6d975857678415f505"
          ]
        },
        "outputId": "20c6562f-7358-4dc7-dada-787bede963bc"
      },
      "source": [
        "batch_size=16  # change to 16 for full training\n",
        "encoder_max_length=256\n",
        "decoder_max_length=64\n",
        "\n",
        "def process_data_to_model_inputs(batch):\n",
        "    # Tokenizer will automatically set [BOS] <text> [EOS]\n",
        "    inputs = tokenizer(batch[\"original\"], padding=\"max_length\", truncation=True, max_length=encoder_max_length)\n",
        "    outputs = tokenizer(batch[\"summary\"], padding=\"max_length\", truncation=True, max_length=decoder_max_length)\n",
        "\n",
        "    batch[\"input_ids\"] = inputs.input_ids\n",
        "    batch[\"attention_mask\"] = inputs.attention_mask\n",
        "    batch[\"decoder_input_ids\"] = outputs.input_ids\n",
        "    batch[\"labels\"] = outputs.input_ids.copy()\n",
        "    # mask loss for padding\n",
        "    batch[\"labels\"] = [\n",
        "        [-100 if token == tokenizer.pad_token_id else token for token in labels] for labels in batch[\"labels\"]\n",
        "    ]\n",
        "    batch[\"decoder_attention_mask\"] = outputs.attention_mask\n",
        "\n",
        "    return batch\n",
        "\n",
        "# only use 32 training examples for notebook - DELETE LINE FOR FULL TRAINING\n",
        "# train_data = train_data.select(range(32))\n",
        "\n",
        "train_data_batch = train_data.map(\n",
        "    process_data_to_model_inputs,\n",
        "    batched=True,\n",
        "    batch_size=batch_size,\n",
        "    remove_columns=[\"file\",\"original\", \"summary\"],\n",
        ")\n",
        "train_data_batch.set_format(\n",
        "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",
        ")\n",
        "\n",
        "\n",
        "# only use 16 training examples for notebook - DELETE LINE FOR FULL TRAINING\n",
        "# val_data = val_data.select(range(16))\n",
        "\n",
        "val_data_batch = val_data.map(\n",
        "    process_data_to_model_inputs,\n",
        "    batched=True,\n",
        "    batch_size=batch_size,\n",
        "    remove_columns=[\"file\", \"original\", \"summary\"],\n",
        ")\n",
        "val_data_batch.set_format(\n",
        "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70bb7c0669ca4a3699ad36dfdcc10910",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=6589.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3ddde0882d841daa3bfde43ed6e6fc9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1416.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEjb026cNC38"
      },
      "source": [
        "### **Warm-starting the Encoder-Decoder Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tS0UndNoQh8t"
      },
      "source": [
        "from transformers import EncoderDecoderModel\n",
        "\n",
        "# set encoder decoder tying to True\n",
        "roberta_shared = EncoderDecoderModel.from_encoder_decoder_pretrained(\"vinai/phobert-base\", \"vinai/phobert-base\", tie_encoder_decoder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD2jv3GkyjR-"
      },
      "source": [
        "# set special tokens\n",
        "roberta_shared.config.decoder_start_token_id = tokenizer.bos_token_id\n",
        "roberta_shared.config.eos_token_id = tokenizer.eos_token_id\n",
        "\n",
        "# sensible parameters for beam search\n",
        "# set decoding params\n",
        "roberta_shared.config.max_length = 64\n",
        "roberta_shared.config.early_stopping = True\n",
        "roberta_shared.config.no_repeat_ngram_size = 3\n",
        "roberta_shared.config.length_penalty = 2.0\n",
        "roberta_shared.config.num_beams = 4\n",
        "roberta_shared.config.vocab_size = roberta_shared.config.encoder.vocab_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u98CLZiTkgzv"
      },
      "source": [
        "### **Fine-Tuning Warm-Started Encoder-Decoder Models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gYzA-w96wCt"
      },
      "source": [
        "The `Seq2SeqTrainer` that can be found under [examples/seq2seq/seq2seq_trainer.py](https://github.com/huggingface/transformers/blob/master/examples/seq2seq/seq2seq_trainer.py) will be used to fine-tune a warm-started encoder-decoder model.\n",
        "\n",
        "Let's download the `Seq2SeqTrainer` code and import the module along with `TrainingArguments`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyiwaF0noA5c"
      },
      "source": [
        "%%capture\n",
        "!rm seq2seq_trainer.py\n",
        "!wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/seq2seq/seq2seq_trainer.py\n",
        "\n",
        "!pip install git-python==1.0.3\n",
        "!pip install sacrebleu==1.4.12\n",
        "!pip install rouge_score\n",
        "\n",
        "from seq2seq_trainer import Seq2SeqTrainer\n",
        "from transformers import TrainingArguments\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Optional"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nmQRT3XuHHz"
      },
      "source": [
        "We need to add some additional parameters to make `TrainingArguments` compatible with the `Seq2SeqTrainer`. Let's just copy the `dataclass` arguments as defined in [this file](https://github.com/patrickvonplaten/transformers/blob/make_seq2seq_trainer_self_contained/examples/seq2seq/finetune_trainer.py)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zkkd66rtsnA"
      },
      "source": [
        "@dataclass\n",
        "class Seq2SeqTrainingArguments(TrainingArguments):\n",
        "    label_smoothing: Optional[float] = field(\n",
        "        default=0.0, metadata={\"help\": \"The label smoothing epsilon to apply (if not zero).\"}\n",
        "    )\n",
        "    sortish_sampler: bool = field(default=False, metadata={\"help\": \"Whether to SortishSamler or not.\"})\n",
        "    predict_with_generate: bool = field(\n",
        "        default=False, metadata={\"help\": \"Whether to use generate to calculate generative metrics (ROUGE, BLEU).\"}\n",
        "    )\n",
        "    adafactor: bool = field(default=False, metadata={\"help\": \"whether to use adafactor\"})\n",
        "    encoder_layerdrop: Optional[float] = field(\n",
        "        default=None, metadata={\"help\": \"Encoder layer dropout probability. Goes into model.config.\"}\n",
        "    )\n",
        "    decoder_layerdrop: Optional[float] = field(\n",
        "        default=None, metadata={\"help\": \"Decoder layer dropout probability. Goes into model.config.\"}\n",
        "    )\n",
        "    dropout: Optional[float] = field(default=None, metadata={\"help\": \"Dropout probability. Goes into model.config.\"})\n",
        "    attention_dropout: Optional[float] = field(\n",
        "        default=None, metadata={\"help\": \"Attention dropout probability. Goes into model.config.\"}\n",
        "    )\n",
        "    lr_scheduler: Optional[str] = field(\n",
        "        default=\"linear\", metadata={\"help\": f\"Which lr scheduler to use.\"}\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPUAgo7pxH24"
      },
      "source": [
        "Also, we need to define a function to correctly compute the ROUGE score during validation. ROUGE is a much better metric to track during training than only language modeling loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQgzLsU_MJyz"
      },
      "source": [
        "import datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68IHmFYLx09W"
      },
      "source": [
        "# load rouge for validation\n",
        "rouge = datasets.load_metric(\"rouge\")\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels_ids = pred.label_ids\n",
        "    pred_ids = pred.predictions\n",
        "\n",
        "    # all unnecessary tokens are removed\n",
        "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
        "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
        "\n",
        "    rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n",
        "\n",
        "    return {\n",
        "        \"rouge2_precision\": round(rouge_output.precision, 4),\n",
        "        \"rouge2_recall\": round(rouge_output.recall, 4),\n",
        "        \"rouge2_fmeasure\": round(rouge_output.fmeasure, 4),\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ik4hZb2yV-b"
      },
      "source": [
        "Cool! Finally, we start training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAaTxUpdzshF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "outputId": "7e103b00-0ac7-41c0-84a4-884932474b22"
      },
      "source": [
        "# set training arguments - these params are not really tuned, feel free to change\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir= OUTPUT_DIR,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    predict_with_generate=True,\n",
        "    # evaluate_during_training=True,\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    logging_steps=200,  # set to 2000 for full training\n",
        "    save_steps=5000,  # set to 500 for full training\n",
        "    eval_steps=7500,  # set to 7500 for full training\n",
        "    warmup_steps=3000,  # set to 3000 for full training\n",
        "    num_train_epochs=10, #uncomment for full training\n",
        "    overwrite_output_dir=True,\n",
        "    save_total_limit=50,\n",
        "    fp16=True,\n",
        ")\n",
        "\n",
        "# instantiate trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=roberta_shared,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=train_data_batch,\n",
        "    eval_dataset=val_data_batch,\n",
        ")\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The `config.pad_token_id` is `None`. Using `config.eos_token_id` = 2 for padding..\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='202' max='65890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  202/65890 02:35 < 14:11:34, 1.29 it/s, Epoch 0.03/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>9.417800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7854KKs6EY4x"
      },
      "source": [
        "!gsutil -m cp -r '/content/training/*' 'gs://kaggle-vbdi-test/training_Data'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwQIEhKOrJpl"
      },
      "source": [
        "### **Evaluation**\n",
        "\n",
        "Awesome, we finished training our dummy model. Let's now evaluated the model on the test data. We make use of the dataset's handy `.map()` function to generate a summary of each sample of the test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOoSrwWarJAC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "0ef7f4e43319429d9277d55c83cb084d",
            "ab543b6ef5b34ed4acb85fd25304ed75",
            "825d4b325e9b45859e808cd6b14fdd42",
            "dd0bdf658c6d4c0cb0a091129ecbebb0",
            "f7c296a0b8a84ee3be45c92edb6aad21",
            "e21d97b40ffa43668b9962c5d771debb",
            "a4898ec38618401396928eee2c4f9926",
            "3598a3c015a64c20be134cf4d2e7fbbe"
          ]
        },
        "outputId": "67b60b74-c47c-4718-82a7-072f85a32c4b"
      },
      "source": [
        "import datasets\n",
        "from transformers import RobertaTokenizer, EncoderDecoderModel, AutoTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\", use_fast=False)\n",
        "\n",
        "model = EncoderDecoderModel.from_pretrained(OUTPUT_DIR + \"/checkpoint-4000\")\n",
        "model.to(\"cuda\")\n",
        "\n",
        "# test_data = datasets.load_dataset(\"xsum\", split=\"test\")\n",
        "\n",
        "batch_size = 16  # change to 64 for full evaluation\n",
        "\n",
        "# map data correctly\n",
        "def generate_summary(batch):\n",
        "    # Tokenizer will automatically set [BOS] <text> [EOS]\n",
        "    inputs = tokenizer(batch[\"original\"], padding=\"max_length\", truncation=True, max_length=256, return_tensors=\"pt\")\n",
        "    input_ids = inputs.input_ids.to(\"cuda\")\n",
        "    attention_mask = inputs.attention_mask.to(\"cuda\")\n",
        "\n",
        "    outputs = model.generate(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    # all special tokens including will be removed\n",
        "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "\n",
        "    batch[\"pred\"] = output_str\n",
        "\n",
        "    return batch\n",
        "\n",
        "results = test_data.map(generate_summary, batched=True, batch_size=batch_size, remove_columns=[\"original\"])\n",
        "\n",
        "pred_str = results[\"pred\"]\n",
        "label_str = results[\"summary\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ef7f4e43319429d9277d55c83cb084d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=22.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHl8NMjEiTb6"
      },
      "source": [
        "rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge1\",\"rouge2\",\"rougeL\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13HUSVh4-CAk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96f5c2c3-439c-41f5-e757-02e9aa568c5a"
      },
      "source": [
        "for key,value in rouge_output.items():\n",
        "  print(key)\n",
        "  print(value.mid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rouge1\n",
            "Score(precision=0.6156883807011324, recall=0.6143045549259318, fmeasure=0.5906751582344583)\n",
            "rouge2\n",
            "Score(precision=0.3081612284527864, recall=0.3055766169704671, fmeasure=0.29421411955015214)\n",
            "rougeL\n",
            "Score(precision=0.4081913955092156, recall=0.405197179436527, fmeasure=0.3907000488647073)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8R5CclwUGuC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b53d98d-8d04-49b5-c55a-d47530564398"
      },
      "source": [
        "i = 154\n",
        "print('Prediction: ',pred_str[i])\n",
        "print('Truth: ',label_str[i])\n",
        "print('Content: ',test_data[i]['original'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction:  Tên trộm đã đột_nhập đền Xã_Tắc ( phường Ka_Long, TP. Móng_Cái ) lấy trộm khoảng 300 triệu đồng từ hòm công_đức.\n",
            "Truth:  Camera tại đền Xã_Tắc ( Quảng_Ninh ) ghi lại hình_ảnh hai thanh_niên cạy cửa đền , dùng thanh sắt và đục phá hỏng 3 chiếc hòm công_đức lấy đi số tiền ước_tính 300 triệu đồng .\n",
            "Content:  Công_an thành_phố Móng_Cái ( Quảng_Ninh ) đang truy_tìm hai nghi phạm trộm tài_sản tại đền Xã_Tắc ở phường Ka_Long . Trước đó , khoảng 2h15 ngày 28/5 , hai thanh_niên đột_nhập đền , cạy cửa , phá hỏng 3 chiếc hòm công_đức lấy đi toàn_bộ tiền bên trong . Tài_sản bị mất ước_chừng 300 triệu đồng , chủ_yếu có mệnh_giá 10.000-50.000 đồng . Hình_ảnh do camera an_ninh ghi lại cho thấy hai nghi phạm tuổi từ 25 đến 30 . Phân_tích các dữ_liệu , cảnh_sát nhận_định , một người cao khoảng 1m65 , miệng rộng , má hóp , dáng gầy , mặc áo_phông ngắn tay màu nâu , đội mũ lưỡi chai màu ghi . Người thứ hai cao khoảng 1m70 , dáng gầy , mặc quần vải màu đen , áo sơmi dài tay tối màu , đội mũ che_kín mặt và đầu . Công_an thành_phố Móng_Cái đề_nghị ai biết thông_tin liên_hệ với Đội cảnh_sát điều_tra về trật_tự xã_hội . Đền Xã_Tắc được xây_dựng khoảng cuối thế_kỷ thứ 13 , nằm ở khu_vực biên_cương của tổ_quốc , bên bờ sông Ka_Long . Đây một trong những di_tích lịch_sử vào loại lâu_đời nhất ở Móng_Cái .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4kLAIQSr5g2",
        "outputId": "b4d745cb-4599-43cf-e8c0-1ec9e5fdba6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test_data[i]['file']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/ViMs/original/Cluster_256/original/1671.txt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D__lCYyZvFhr"
      },
      "source": [
        "rdrsegmenter = VnCoreNLP(\"./vncorenlp/VnCoreNLP-1.1.1.jar\", annotators=\"wseg\", max_heap_size='-Xmx2g')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWa2uIUHzY1R"
      },
      "source": [
        "text = '''\n",
        " Ngày 4/2, lãnh đạo thị xã Hoàng Mai (Nghệ An) cho biết, cơ quan chức năng thị xã vừa phối hợp với đơn vị chức năng tỉnh cách ly, lấy mẫu xét nghiệm cho 1 nam sinh viên trường Đại học FPT có biểu hiện ho sốt sau khi đi từ Hà Nội về nhà.\n",
        "\n",
        "Trước đó vào ngày 31/1 nam sinh C.T.Ph. (20 tuổi, trú TX. Hoàng Mai, Nghệ An; Sinh viên trường Đại học FPT cơ sở Mỹ Đình) cùng 1 người bạn đi xe máy từ Hà Nội về quê nhà.\n",
        "\n",
        "Lúc 22h ngày 31/1 nam sinh này về đến quê nhà nhưng không khai báo y tế. Từ ngày 1-3/2, nam sinh Ph. có đi một số nơi trên địa bàn thị xã và tiếp xúc với khoảng 12 người.\n",
        "\n",
        "\n",
        "Khoảng 20h ngày 3/2, nam sinh này có dấu hiệu sốt 39 độ, đau đầu, đau rát họng, đau mỏi cơ, khó thở nhẹ. Nam sinh này sau đó được đưa vào Bệnh viện Phong da liễu (TX. Hoàng Mai) để khám và cách ly y tế.\n",
        "\n",
        "Nhận được tin báo, Trung tâm Kiểm soát bệnh tật tỉnh Nghệ An đã trực tiếp ra lấy mẫu bệnh phẩm để xét nghiệm Covid-19. Dự kiến trong chiều cùng ngày sẽ có kết quả.\n",
        "\n",
        "Hiện cơ quan chức năng đang rà soát những người tiếp xúc gần với nam sinh Ph. để có phương án theo dõi, cách ly và lấy mẫu xét nghiệm.\n",
        "\n",
        "Trước đó vào đêm 31/1, một chuyến xe khách chở 22 người từ Hà Nội về Nghệ An trong đó có nhiều sinh viên Đại học FPT đi về tại phường Lê Lợi, TP. Vinh (Nghệ An). Cơ quan chức năng sau đó đã đưa 1 trường hợp F1 trên xe khách này đi cách ly tại Trung tâm Y tế huyện Nam Đàn. Riêng những trường hợp còn lại được theo dõi tại nhà.\n",
        "\n",
        "Sau khi cách ly, các trường hợp này đã được lấy mẫu xét nghiệm và cho kết quả âm tính với Covid-19.\n",
        " '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUXmH90UznVP",
        "outputId": "7f910890-57f6-4198-f0d0-6c9d5a13cac5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "text = rdrsegmenter.tokenize(text)\n",
        "text = ' '.join([' '.join(x) for x in text])\n",
        "text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Ngày 4/2 , lãnh_đạo thị_xã Hoàng_Mai ( Nghệ_An ) cho biết , cơ_quan_chức_năng thị_xã vừa phối_hợp với đơn_vị chức_năng tỉnh cách_ly , lấy mẫu xét_nghiệm cho 1 nam sinh_viên trường Đại_học FPT có biểu_hiện ho sốt sau khi đi từ Hà_Nội về nhà . Trước đó vào ngày 31/1 nam_sinh C.T.Ph. ( 20 tuổi , trú TX . Hoàng_Mai , Nghệ_An ; Sinh_viên trường Đại_học FPT cơ_sở Mỹ_Đình ) cùng 1 người bạn đi xe_máy từ Hà_Nội về quê nhà . Lúc 22h ngày 31/1 nam_sinh này về đến quê nhà nhưng không khai_báo y_tế . Từ ngày 1-3/2 , nam_sinh Ph . có đi một_số nơi trên địa_bàn thị_xã và tiếp_xúc với khoảng 12 người . Khoảng 20h ngày 3/2 , nam_sinh này có dấu_hiệu sốt 39 độ , đau_đầu , đau rát họng , đau mỏi cơ , khó thở nhẹ . Nam_sinh này sau đó được đưa vào Bệnh_viện Phong da_liễu ( TX . Hoàng_Mai ) để khám và cách_ly y_tế . Nhận được tin báo , Trung_tâm Kiểm_soát bệnh_tật tỉnh Nghệ_An đã trực_tiếp ra lấy mẫu bệnh_phẩm để xét_nghiệm Covid-19 . Dự_kiến trong chiều cùng ngày sẽ có kết_quả . Hiện cơ_quan_chức_năng đang rà_soát những người tiếp_xúc gần với nam_sinh Ph . để có phương_án theo_dõi , cách_ly và lấy mẫu xét_nghiệm . Trước đó vào đêm 31/1 , một chuyến xe_khách chở 22 người từ Hà_Nội về Nghệ_An trong đó có nhiều sinh_viên Đại_học FPT đi về tại phường Lê_Lợi , TP. Vinh ( Nghệ_An ) . Cơ_quan_chức_năng sau đó đã đưa 1 trường_hợp F1 trên xe_khách này đi cách_ly tại Trung_tâm Y_tế huyện Nam_Đàn . Riêng những trường_hợp còn lại được theo_dõi tại nhà . Sau khi cách_ly , các trường_hợp này đã được lấy mẫu xét_nghiệm và cho kết_quả âm_tính với Covid-19 .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCQ5zA96zuzu",
        "outputId": "3f12d605-3f82-451b-ee4d-349ebe54edec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "inputs = tokenizer(text, padding=\"max_length\", truncation=True, max_length=256, return_tensors=\"pt\")\n",
        "input_ids = inputs.input_ids.to(\"cuda\")\n",
        "attention_mask = inputs.attention_mask.to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "# all special tokens including will be removed\n",
        "output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "output_str"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Trong người bạn gái của một cán_bộ Công_an tỉnh Nghệ_An cho biết, đơn_vị đang khẩn_trương điều_tra, xác_minh nguyên_nhân khiến một nam thanh_niên tử_vong.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H06_kgjD3ftO"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}