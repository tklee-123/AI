{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "testing-huggingface",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0ef7f4e43319429d9277d55c83cb084d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ab543b6ef5b34ed4acb85fd25304ed75",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_825d4b325e9b45859e808cd6b14fdd42",
              "IPY_MODEL_dd0bdf658c6d4c0cb0a091129ecbebb0"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "ab543b6ef5b34ed4acb85fd25304ed75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "825d4b325e9b45859e808cd6b14fdd42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f7c296a0b8a84ee3be45c92edb6aad21",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 22,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 22,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e21d97b40ffa43668b9962c5d771debb"
          },
          "model_module_version": "1.5.0"
        },
        "dd0bdf658c6d4c0cb0a091129ecbebb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a4898ec38618401396928eee2c4f9926",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 22/22 [29:59&lt;00:00, 81.81s/ba]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3598a3c015a64c20be134cf4d2e7fbbe"
          },
          "model_module_version": "1.5.0"
        },
        "f7c296a0b8a84ee3be45c92edb6aad21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "e21d97b40ffa43668b9962c5d771debb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "a4898ec38618401396928eee2c4f9926": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "3598a3c015a64c20be134cf4d2e7fbbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "685890703d354cd09f2214bd9efad65e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8a66dbd9525f4abc988264edec2a0723",
              "IPY_MODEL_d7fa7a9cfbe643aa8958287d6f4f23f1",
              "IPY_MODEL_fba4356dd3974e498916c010d1e3bdcb"
            ],
            "layout": "IPY_MODEL_ce20e4a5730049919ce6ec4e8e60cf01"
          }
        },
        "8a66dbd9525f4abc988264edec2a0723": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b23bfb7f0914fc7b3f448814c91c741",
            "placeholder": "​",
            "style": "IPY_MODEL_6f41627bd3d74df4849136d842b3bed7",
            "value": "100%"
          }
        },
        "d7fa7a9cfbe643aa8958287d6f4f23f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7516e4c5af524007a7c11b8245f76ed7",
            "max": 6589,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d4ad4a2c27fe4e0d96e337105c3ca36d",
            "value": 6589
          }
        },
        "fba4356dd3974e498916c010d1e3bdcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_247fb92174384ffabd04bd2cf38272b6",
            "placeholder": "​",
            "style": "IPY_MODEL_53684c279d604769a51e81325c23fdb1",
            "value": " 6589/6589 [05:31&lt;00:00, 21.32ba/s]"
          }
        },
        "ce20e4a5730049919ce6ec4e8e60cf01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b23bfb7f0914fc7b3f448814c91c741": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f41627bd3d74df4849136d842b3bed7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7516e4c5af524007a7c11b8245f76ed7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4ad4a2c27fe4e0d96e337105c3ca36d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "247fb92174384ffabd04bd2cf38272b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53684c279d604769a51e81325c23fdb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0623bbddaf6c47649be14bea010055a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11271ef49f184811877db3084c698c99",
              "IPY_MODEL_807a28753b2341f9970b7b30a01a9e1a",
              "IPY_MODEL_433865a074874d128e71c4bcfe95d80d"
            ],
            "layout": "IPY_MODEL_95a36ac11cff478bb5f9b5c7d65e53c0"
          }
        },
        "11271ef49f184811877db3084c698c99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7e072b78bad46c88bc24d64653e6902",
            "placeholder": "​",
            "style": "IPY_MODEL_8c5bf48c98dd4327a3defcb1b0ed3052",
            "value": "100%"
          }
        },
        "807a28753b2341f9970b7b30a01a9e1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c565dfeb790c4da6aa433c2d4bc333aa",
            "max": 1416,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf5e9bacaae44462a7a56db2fffdaad2",
            "value": 1416
          }
        },
        "433865a074874d128e71c4bcfe95d80d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2137a6cf552f46c28fcf64f08dfb8b43",
            "placeholder": "​",
            "style": "IPY_MODEL_b21c58a4aabe441e9926f10f013d4cc9",
            "value": " 1416/1416 [01:10&lt;00:00, 21.00ba/s]"
          }
        },
        "95a36ac11cff478bb5f9b5c7d65e53c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7e072b78bad46c88bc24d64653e6902": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c5bf48c98dd4327a3defcb1b0ed3052": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c565dfeb790c4da6aa433c2d4bc333aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf5e9bacaae44462a7a56db2fffdaad2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2137a6cf552f46c28fcf64f08dfb8b43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b21c58a4aabe441e9926f10f013d4cc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tklee-123/AI/blob/main/notebooks/training_vietnews.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6hRf-gcm92k"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgp6VBA8DQ-l",
        "outputId": "b772da18-82c6-427f-c35b-ac927f314fd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Authenticate\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "print('Authenticated')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authenticated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gx4Vg4cbEUJ_"
      },
      "source": [
        "OUTPUT_DIR = '/content/training/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVUAENd5DYp6"
      },
      "source": [
        "import random\n",
        "\n",
        "random.seed(0)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_GCCIaj7ulj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73079cd6-5d45-4ab2-c31a-92621c7d7551"
      },
      "source": [
        "!wget 'https://github.com/ThanhChinhBK/vietnews/archive/master.zip'\n",
        "!unzip 'master.zip'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-29 10:17:01--  https://github.com/ThanhChinhBK/vietnews/archive/master.zip\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/ThanhChinhBK/vietnews/zip/refs/heads/master [following]\n",
            "--2025-08-29 10:17:01--  https://codeload.github.com/ThanhChinhBK/vietnews/zip/refs/heads/master\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.114.9\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.114.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘master.zip.1’\n",
            "\n",
            "master.zip.1            [        <=>         ]  61.64M  11.7MB/s               ^C\n",
            "Archive:  master.zip\n",
            "a20d9b7f5d37b95f39f28f08999092f9fa400983\n",
            "replace vietnews-master/data/test_tokenized/000001.txt.seg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzywNFmeKVgx"
      },
      "source": [
        "%%capture\n",
        "\n",
        "# !wget 'https://github.com/CLC-HCMUS/ViMs-Dataset/raw/master/ViMs.zip'\n",
        "# !unzip 'ViMs.zip'\n",
        "\n",
        "# Install the vncorenlp python wrapper\n",
        "!pip install vncorenlp\n",
        "\n",
        "# Download VnCoreNLP-1.1.1.jar & its word segmentation component (i.e. RDRSegmenter)\n",
        "!mkdir -p vncorenlp/models/wordsegmenter\n",
        "!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\n",
        "!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab\n",
        "!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\n",
        "!mv VnCoreNLP-1.1.1.jar vncorenlp/\n",
        "!mv vi-vocab vncorenlp/models/wordsegmenter/\n",
        "!mv wordsegmenter.rdr vncorenlp/models/wordsegmenter/\n",
        "!pip install datasets==1.0.2"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZYjioRkKviO"
      },
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "import concurrent.futures\n",
        "from datasets import *"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IteMtlc58-y"
      },
      "source": [
        "## Processing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWuj00alIK5D"
      },
      "source": [
        "from vncorenlp import VnCoreNLP\n",
        "rdrsegmenter = VnCoreNLP(\"./vncorenlp/VnCoreNLP-1.1.1.jar\", annotators=\"wseg\", max_heap_size='-Xmx2g')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVkc5HmK6Bdd"
      },
      "source": [
        "def listPaths(path):\n",
        "  pathfiles = list()\n",
        "  for pathfile in glob.glob(path):\n",
        "    pathfiles.append(pathfile)\n",
        "  return pathfiles\n",
        "\n",
        "train_paths = listPaths('/content/vietnews-master/data/train_tokenized/*')\n",
        "val_paths = listPaths('/content/vietnews-master/data/val_tokenized/*')\n",
        "test_paths = listPaths('/content/vietnews-master/data/test_tokenized/*')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ8pgIYN7zSW"
      },
      "source": [
        "def read_content(pathfile):\n",
        "  \"\"\"\n",
        "  Input: Path of txt file\n",
        "  Output: A dictionary has keys 'original' and 'summary'\n",
        "  \"\"\"\n",
        "  with open(pathfile) as f:\n",
        "    rows  = f.readlines()\n",
        "    original = ' '.join(''.join(rows[4:]).split('\\n'))\n",
        "    summary = ' '.join(rows[2].split('\\n'))\n",
        "\n",
        "  return {'file' : pathfile,\n",
        "            'original': original,\n",
        "            'summary': summary}"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_716GF2iDTcD",
        "outputId": "84311b11-9280-4a84-dae9-3a99cf455eb3"
      },
      "source": [
        "read_content(train_paths[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'file': '/content/vietnews-master/data/train_tokenized/102818.txt.seg',\n",
              " 'original': 'Chiều 4/11 , ông Nguyễn_Thế_Hùng - Phó chủ_tịch UBND TP Hội_An , cho_biết do ảnh_hưởng của bão số 12 kết_hợp không_khí lạnh , nước_biển đã xâm_thực mạnh vào bờ biển Cửa_Đại , nhiều nơi sóng đánh cao khoảng 10 mét gây sạt_lở . Sóng đánh cao 10 mét ở Cửa_Đại ( Hội_An ) . Một_số tuyến phố Hội_An ngập nước khoảng 30 cm , trong khi nước lũ đang lên nhanh . TP Hội_An ra thông_báo trên loa phát_thanh về việc thuỷ_điện sông Tranh 2 xả lũ vào chiều cùng ngày từ 500 đến 1.500 m3 / s . Từ 18h ngày 4/1 , thuỷ_điện sông Tranh 2 xả lũ 2.000 đến 3.500 m3 / s . Việc thuỷ_điện xả lũ kết_hợp mưa lớn khiến TP Hội_An xuất hơn đợt lũ được dự_báo trên báo_động báo ba từ ngày_mai , khả_năng đạt đỉnh lũ năm 2016 . “ Các cơ_quan , đơn_vị , xã phường triển_khai trực 24/24 để theo_dõi tình_hình ; chuẩn_bị đầy_đủ vật_tư , phương_tiện để chủ_động phòng_chống lũ ” , ông Hùng nói . TP Hội_An đã triển_khai phương_án di_dời tại_chỗ với các hộ dân vùng thấp trũng để đề_phòng nước lũ dâng cao . Sáng 2/11 áp_thấp_nhiệt_đới mạnh lên thành bão , cơn bão thứ 12 trên biển Đông , tên quốc_tế là Damrey . Bão tăng cấp rất nhanh khi tiến sát bờ biển Nam_Trung_Bộ do kết_hợp với không_khí lạnh . 6h ngày 4/11 , bão đổ_bộ Phú_Yên - Khánh_Hoà , mạnh cấp 12 ( 135 km/h ) . Tiến sâu vào nam Tây_Nguyên , bão giảm còn cấp 9 ( 90 km/h ) và đến 15h cùng ngày thì suy_yếu thành áp_thấp_nhiệt_đới khi ở biên_giới Việt_Nam - Campuchia . Trong 9 tiếng hoành_hành , bão đã gây gió mạnh , mưa to suốt từ Thừa_Thiên_Huế tới Bình_Thuận và các tỉnh Tây_Nguyên . Thống_kê sơ_bộ 20 người đã chết , 17 người mất_tích . Tỉnh Khánh_Hoà , Phú_Yên mất điện .   Sóng đánh cao 10 mét ở Cửa_Đại ( Hội_An ) . Đường Bạch_Đằng trong phố cổ Hội_An ngập 30 cm . ',\n",
              " 'summary': 'Sóng đánh bờ biển Cửa_Đại ( Hội_An ) cao khoảng 10 mét , một_số tuyến đường trong phố cổ ngập 30 cm . '}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wm5kLJD_840E"
      },
      "source": [
        "def get_dataframe(pathfiles):\n",
        "  with concurrent.futures.ProcessPoolExecutor() as executor:\n",
        "    data = executor.map(read_content, pathfiles)\n",
        "\n",
        "  # Make blank dataframe\n",
        "  data_df = list()\n",
        "  for d in data:\n",
        "    data_df.append(d)\n",
        "  data_df = pd.DataFrame(data_df)\n",
        "  data_df.dropna(inplace = True)\n",
        "  data_df = data_df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "  return data_df"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4c0pl5BAl3f"
      },
      "source": [
        "train_df = get_dataframe(train_paths)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "JsIfrFdlHNDU",
        "outputId": "b115a613-d566-480b-83f3-a3213b95cd4e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pandas.core.frame.DataFrame</b><br/>def __init__(data=None, index: Axes | None=None, columns: Axes | None=None, dtype: Dtype | None=None, copy: bool | None=None) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py</a>Two-dimensional, size-mutable, potentially heterogeneous tabular data.\n",
              "\n",
              "Data structure also contains labeled axes (rows and columns).\n",
              "Arithmetic operations align on both row and column labels. Can be\n",
              "thought of as a dict-like container for Series objects. The primary\n",
              "pandas data structure.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "data : ndarray (structured or homogeneous), Iterable, dict, or DataFrame\n",
              "    Dict can contain Series, arrays, constants, dataclass or list-like objects. If\n",
              "    data is a dict, column order follows insertion-order. If a dict contains Series\n",
              "    which have an index defined, it is aligned by its index. This alignment also\n",
              "    occurs if data is a Series or a DataFrame itself. Alignment is done on\n",
              "    Series/DataFrame inputs.\n",
              "\n",
              "    If data is a list of dicts, column order follows insertion-order.\n",
              "\n",
              "index : Index or array-like\n",
              "    Index to use for resulting frame. Will default to RangeIndex if\n",
              "    no indexing information part of input data and no index provided.\n",
              "columns : Index or array-like\n",
              "    Column labels to use for resulting frame when data does not have them,\n",
              "    defaulting to RangeIndex(0, 1, 2, ..., n). If data contains column labels,\n",
              "    will perform column selection instead.\n",
              "dtype : dtype, default None\n",
              "    Data type to force. Only a single dtype is allowed. If None, infer.\n",
              "copy : bool or None, default None\n",
              "    Copy data from inputs.\n",
              "    For dict data, the default of None behaves like ``copy=True``.  For DataFrame\n",
              "    or 2d ndarray input, the default of None behaves like ``copy=False``.\n",
              "    If data is a dict containing one or more Series (possibly of different dtypes),\n",
              "    ``copy=False`` will ensure that these inputs are not copied.\n",
              "\n",
              "    .. versionchanged:: 1.3.0\n",
              "\n",
              "See Also\n",
              "--------\n",
              "DataFrame.from_records : Constructor from tuples, also record arrays.\n",
              "DataFrame.from_dict : From dicts of Series, arrays, or dicts.\n",
              "read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
              "read_table : Read general delimited file into DataFrame.\n",
              "read_clipboard : Read text from clipboard into DataFrame.\n",
              "\n",
              "Notes\n",
              "-----\n",
              "Please reference the :ref:`User Guide &lt;basics.dataframe&gt;` for more information.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "Constructing DataFrame from a dictionary.\n",
              "\n",
              "&gt;&gt;&gt; d = {&#x27;col1&#x27;: [1, 2], &#x27;col2&#x27;: [3, 4]}\n",
              "&gt;&gt;&gt; df = pd.DataFrame(data=d)\n",
              "&gt;&gt;&gt; df\n",
              "   col1  col2\n",
              "0     1     3\n",
              "1     2     4\n",
              "\n",
              "Notice that the inferred dtype is int64.\n",
              "\n",
              "&gt;&gt;&gt; df.dtypes\n",
              "col1    int64\n",
              "col2    int64\n",
              "dtype: object\n",
              "\n",
              "To enforce a single dtype:\n",
              "\n",
              "&gt;&gt;&gt; df = pd.DataFrame(data=d, dtype=np.int8)\n",
              "&gt;&gt;&gt; df.dtypes\n",
              "col1    int8\n",
              "col2    int8\n",
              "dtype: object\n",
              "\n",
              "Constructing DataFrame from a dictionary including Series:\n",
              "\n",
              "&gt;&gt;&gt; d = {&#x27;col1&#x27;: [0, 1, 2, 3], &#x27;col2&#x27;: pd.Series([2, 3], index=[2, 3])}\n",
              "&gt;&gt;&gt; pd.DataFrame(data=d, index=[0, 1, 2, 3])\n",
              "   col1  col2\n",
              "0     0   NaN\n",
              "1     1   NaN\n",
              "2     2   2.0\n",
              "3     3   3.0\n",
              "\n",
              "Constructing DataFrame from numpy ndarray:\n",
              "\n",
              "&gt;&gt;&gt; df2 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),\n",
              "...                    columns=[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;])\n",
              "&gt;&gt;&gt; df2\n",
              "   a  b  c\n",
              "0  1  2  3\n",
              "1  4  5  6\n",
              "2  7  8  9\n",
              "\n",
              "Constructing DataFrame from a numpy ndarray that has labeled columns:\n",
              "\n",
              "&gt;&gt;&gt; data = np.array([(1, 2, 3), (4, 5, 6), (7, 8, 9)],\n",
              "...                 dtype=[(&quot;a&quot;, &quot;i4&quot;), (&quot;b&quot;, &quot;i4&quot;), (&quot;c&quot;, &quot;i4&quot;)])\n",
              "&gt;&gt;&gt; df3 = pd.DataFrame(data, columns=[&#x27;c&#x27;, &#x27;a&#x27;])\n",
              "...\n",
              "&gt;&gt;&gt; df3\n",
              "   c  a\n",
              "0  3  1\n",
              "1  6  4\n",
              "2  9  7\n",
              "\n",
              "Constructing DataFrame from dataclass:\n",
              "\n",
              "&gt;&gt;&gt; from dataclasses import make_dataclass\n",
              "&gt;&gt;&gt; Point = make_dataclass(&quot;Point&quot;, [(&quot;x&quot;, int), (&quot;y&quot;, int)])\n",
              "&gt;&gt;&gt; pd.DataFrame([Point(0, 0), Point(0, 3), Point(2, 3)])\n",
              "   x  y\n",
              "0  0  0\n",
              "1  0  3\n",
              "2  2  3\n",
              "\n",
              "Constructing DataFrame from Series/DataFrame:\n",
              "\n",
              "&gt;&gt;&gt; ser = pd.Series([1, 2, 3], index=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;])\n",
              "&gt;&gt;&gt; df = pd.DataFrame(data=ser, index=[&quot;a&quot;, &quot;c&quot;])\n",
              "&gt;&gt;&gt; df\n",
              "   0\n",
              "a  1\n",
              "c  3\n",
              "\n",
              "&gt;&gt;&gt; df1 = pd.DataFrame([1, 2, 3], index=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;], columns=[&quot;x&quot;])\n",
              "&gt;&gt;&gt; df2 = pd.DataFrame(data=df1, index=[&quot;a&quot;, &quot;c&quot;])\n",
              "&gt;&gt;&gt; df2\n",
              "   x\n",
              "a  1\n",
              "c  3</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 509);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgMgMnisA0cf"
      },
      "source": [
        "val_df = get_dataframe(val_paths)\n",
        "test_df = get_dataframe(test_paths)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1F58j028eTV"
      },
      "source": [
        "## **Warm-starting RoBERTaShared for BBC XSum**\n",
        "\n",
        "***Note***: This notebook only uses a few training, validation, and test data samples for demonstration purposes. To fine-tune an encoder-decoder model on the full training data, the user should change the training and data preprocessing parameters accordingly as highlighted by the comments.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FO5ESocXvlK"
      },
      "source": [
        "### **Data Preprocessing**\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dill==0.3.5.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "jUycx7pwJZk5",
        "outputId": "e596abc2-9998-451c-deb5-93bfa6b82509"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dill==0.3.5.1\n",
            "  Using cached dill-0.3.5.1-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Using cached dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n",
            "Installing collected packages: dill\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.8\n",
            "    Uninstalling dill-0.3.8:\n",
            "      Successfully uninstalled dill-0.3.8\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "evaluate 0.4.5 requires datasets>=2.0.0, but you have datasets 1.0.2 which is incompatible.\n",
            "multiprocess 0.70.16 requires dill>=0.3.8, but you have dill 0.3.5.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dill-0.3.5.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dill"
                ]
              },
              "id": "c6f9040c97734812a0ca9b069914c6be"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w67vkz3KP9eZ"
      },
      "source": [
        "%%capture\n",
        "!pip install datasets==1.0.2\n",
        "!pip install transformers\n",
        "\n",
        "import datasets\n",
        "import transformers"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgTiC0rhMb7C"
      },
      "source": [
        "from transformers import RobertaTokenizerFast,AutoTokenizer\n",
        "\n",
        "# phobert = AutoModel.from_pretrained(\"vinai/phobert-base\")\n",
        "\n",
        "# For transformers v4.x+:\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\", use_fast=False)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U08MrUK9LcUM"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data =  Dataset.from_pandas(train_df)\n",
        "val_data =  Dataset.from_pandas(val_df)\n",
        "test_data =  Dataset.from_pandas(test_df)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoN2q0hZUbXN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "685890703d354cd09f2214bd9efad65e",
            "8a66dbd9525f4abc988264edec2a0723",
            "d7fa7a9cfbe643aa8958287d6f4f23f1",
            "fba4356dd3974e498916c010d1e3bdcb",
            "ce20e4a5730049919ce6ec4e8e60cf01",
            "2b23bfb7f0914fc7b3f448814c91c741",
            "6f41627bd3d74df4849136d842b3bed7",
            "7516e4c5af524007a7c11b8245f76ed7",
            "d4ad4a2c27fe4e0d96e337105c3ca36d",
            "247fb92174384ffabd04bd2cf38272b6",
            "53684c279d604769a51e81325c23fdb1",
            "0623bbddaf6c47649be14bea010055a1",
            "11271ef49f184811877db3084c698c99",
            "807a28753b2341f9970b7b30a01a9e1a",
            "433865a074874d128e71c4bcfe95d80d",
            "95a36ac11cff478bb5f9b5c7d65e53c0",
            "d7e072b78bad46c88bc24d64653e6902",
            "8c5bf48c98dd4327a3defcb1b0ed3052",
            "c565dfeb790c4da6aa433c2d4bc333aa",
            "bf5e9bacaae44462a7a56db2fffdaad2",
            "2137a6cf552f46c28fcf64f08dfb8b43",
            "b21c58a4aabe441e9926f10f013d4cc9"
          ]
        },
        "outputId": "12c2dc1f-3cc7-47e0-91be-e0b886609ba6"
      },
      "source": [
        "batch_size=16  # change to 16 for full training\n",
        "encoder_max_length=256\n",
        "decoder_max_length=64\n",
        "\n",
        "def process_data_to_model_inputs(batch):\n",
        "    # Tokenizer will automatically set [BOS] <text> [EOS]\n",
        "    inputs = tokenizer(batch[\"original\"], padding=\"max_length\", truncation=True, max_length=encoder_max_length)\n",
        "    outputs = tokenizer(batch[\"summary\"], padding=\"max_length\", truncation=True, max_length=decoder_max_length)\n",
        "\n",
        "    batch[\"input_ids\"] = inputs.input_ids\n",
        "    batch[\"attention_mask\"] = inputs.attention_mask\n",
        "    batch[\"decoder_input_ids\"] = outputs.input_ids\n",
        "    batch[\"labels\"] = outputs.input_ids.copy()\n",
        "    # mask loss for padding\n",
        "    batch[\"labels\"] = [\n",
        "        [-100 if token == tokenizer.pad_token_id else token for token in labels] for labels in batch[\"labels\"]\n",
        "    ]\n",
        "    batch[\"decoder_attention_mask\"] = outputs.attention_mask\n",
        "\n",
        "    return batch\n",
        "\n",
        "# only use 32 training examples for notebook - DELETE LINE FOR FULL TRAINING\n",
        "# train_data = train_data.select(range(32))\n",
        "\n",
        "train_data_batch = train_data.map(\n",
        "    process_data_to_model_inputs,\n",
        "    batched=True,\n",
        "    batch_size=batch_size,\n",
        "    remove_columns=[\"file\",\"original\", \"summary\"],\n",
        ")\n",
        "train_data_batch.set_format(\n",
        "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",
        ")\n",
        "\n",
        "\n",
        "# only use 16 training examples for notebook - DELETE LINE FOR FULL TRAINING\n",
        "# val_data = val_data.select(range(16))\n",
        "\n",
        "val_data_batch = val_data.map(\n",
        "    process_data_to_model_inputs,\n",
        "    batched=True,\n",
        "    batch_size=batch_size,\n",
        "    remove_columns=[\"file\", \"original\", \"summary\"],\n",
        ")\n",
        "val_data_batch.set_format(\n",
        "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/6589 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "685890703d354cd09f2214bd9efad65e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1416 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0623bbddaf6c47649be14bea010055a1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEjb026cNC38"
      },
      "source": [
        "### **Warm-starting the Encoder-Decoder Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tS0UndNoQh8t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b9b5586-1792-476d-a7d5-48226e6798fa"
      },
      "source": [
        "from transformers import EncoderDecoderModel\n",
        "\n",
        "# set encoder decoder tying to True\n",
        "roberta_shared = EncoderDecoderModel.from_encoder_decoder_pretrained(\"vinai/phobert-base\", \"vinai/phobert-base\", tie_encoder_decoder=True)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForCausalLM were not initialized from the model checkpoint at vinai/phobert-base and are newly initialized: ['roberta.encoder.layer.0.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.0.crossattention.output.dense.bias', 'roberta.encoder.layer.0.crossattention.output.dense.weight', 'roberta.encoder.layer.0.crossattention.self.key.bias', 'roberta.encoder.layer.0.crossattention.self.key.weight', 'roberta.encoder.layer.0.crossattention.self.query.bias', 'roberta.encoder.layer.0.crossattention.self.query.weight', 'roberta.encoder.layer.0.crossattention.self.value.bias', 'roberta.encoder.layer.0.crossattention.self.value.weight', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.1.crossattention.output.dense.bias', 'roberta.encoder.layer.1.crossattention.output.dense.weight', 'roberta.encoder.layer.1.crossattention.self.key.bias', 'roberta.encoder.layer.1.crossattention.self.key.weight', 'roberta.encoder.layer.1.crossattention.self.query.bias', 'roberta.encoder.layer.1.crossattention.self.query.weight', 'roberta.encoder.layer.1.crossattention.self.value.bias', 'roberta.encoder.layer.1.crossattention.self.value.weight', 'roberta.encoder.layer.10.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.10.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.10.crossattention.output.dense.bias', 'roberta.encoder.layer.10.crossattention.output.dense.weight', 'roberta.encoder.layer.10.crossattention.self.key.bias', 'roberta.encoder.layer.10.crossattention.self.key.weight', 'roberta.encoder.layer.10.crossattention.self.query.bias', 'roberta.encoder.layer.10.crossattention.self.query.weight', 'roberta.encoder.layer.10.crossattention.self.value.bias', 'roberta.encoder.layer.10.crossattention.self.value.weight', 'roberta.encoder.layer.11.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.11.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.11.crossattention.output.dense.bias', 'roberta.encoder.layer.11.crossattention.output.dense.weight', 'roberta.encoder.layer.11.crossattention.self.key.bias', 'roberta.encoder.layer.11.crossattention.self.key.weight', 'roberta.encoder.layer.11.crossattention.self.query.bias', 'roberta.encoder.layer.11.crossattention.self.query.weight', 'roberta.encoder.layer.11.crossattention.self.value.bias', 'roberta.encoder.layer.11.crossattention.self.value.weight', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.2.crossattention.output.dense.bias', 'roberta.encoder.layer.2.crossattention.output.dense.weight', 'roberta.encoder.layer.2.crossattention.self.key.bias', 'roberta.encoder.layer.2.crossattention.self.key.weight', 'roberta.encoder.layer.2.crossattention.self.query.bias', 'roberta.encoder.layer.2.crossattention.self.query.weight', 'roberta.encoder.layer.2.crossattention.self.value.bias', 'roberta.encoder.layer.2.crossattention.self.value.weight', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.3.crossattention.output.dense.bias', 'roberta.encoder.layer.3.crossattention.output.dense.weight', 'roberta.encoder.layer.3.crossattention.self.key.bias', 'roberta.encoder.layer.3.crossattention.self.key.weight', 'roberta.encoder.layer.3.crossattention.self.query.bias', 'roberta.encoder.layer.3.crossattention.self.query.weight', 'roberta.encoder.layer.3.crossattention.self.value.bias', 'roberta.encoder.layer.3.crossattention.self.value.weight', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.4.crossattention.output.dense.bias', 'roberta.encoder.layer.4.crossattention.output.dense.weight', 'roberta.encoder.layer.4.crossattention.self.key.bias', 'roberta.encoder.layer.4.crossattention.self.key.weight', 'roberta.encoder.layer.4.crossattention.self.query.bias', 'roberta.encoder.layer.4.crossattention.self.query.weight', 'roberta.encoder.layer.4.crossattention.self.value.bias', 'roberta.encoder.layer.4.crossattention.self.value.weight', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.5.crossattention.output.dense.bias', 'roberta.encoder.layer.5.crossattention.output.dense.weight', 'roberta.encoder.layer.5.crossattention.self.key.bias', 'roberta.encoder.layer.5.crossattention.self.key.weight', 'roberta.encoder.layer.5.crossattention.self.query.bias', 'roberta.encoder.layer.5.crossattention.self.query.weight', 'roberta.encoder.layer.5.crossattention.self.value.bias', 'roberta.encoder.layer.5.crossattention.self.value.weight', 'roberta.encoder.layer.6.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.6.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.6.crossattention.output.dense.bias', 'roberta.encoder.layer.6.crossattention.output.dense.weight', 'roberta.encoder.layer.6.crossattention.self.key.bias', 'roberta.encoder.layer.6.crossattention.self.key.weight', 'roberta.encoder.layer.6.crossattention.self.query.bias', 'roberta.encoder.layer.6.crossattention.self.query.weight', 'roberta.encoder.layer.6.crossattention.self.value.bias', 'roberta.encoder.layer.6.crossattention.self.value.weight', 'roberta.encoder.layer.7.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.7.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.7.crossattention.output.dense.bias', 'roberta.encoder.layer.7.crossattention.output.dense.weight', 'roberta.encoder.layer.7.crossattention.self.key.bias', 'roberta.encoder.layer.7.crossattention.self.key.weight', 'roberta.encoder.layer.7.crossattention.self.query.bias', 'roberta.encoder.layer.7.crossattention.self.query.weight', 'roberta.encoder.layer.7.crossattention.self.value.bias', 'roberta.encoder.layer.7.crossattention.self.value.weight', 'roberta.encoder.layer.8.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.8.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.8.crossattention.output.dense.bias', 'roberta.encoder.layer.8.crossattention.output.dense.weight', 'roberta.encoder.layer.8.crossattention.self.key.bias', 'roberta.encoder.layer.8.crossattention.self.key.weight', 'roberta.encoder.layer.8.crossattention.self.query.bias', 'roberta.encoder.layer.8.crossattention.self.query.weight', 'roberta.encoder.layer.8.crossattention.self.value.bias', 'roberta.encoder.layer.8.crossattention.self.value.weight', 'roberta.encoder.layer.9.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.9.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.9.crossattention.output.dense.bias', 'roberta.encoder.layer.9.crossattention.output.dense.weight', 'roberta.encoder.layer.9.crossattention.self.key.bias', 'roberta.encoder.layer.9.crossattention.self.key.weight', 'roberta.encoder.layer.9.crossattention.self.query.bias', 'roberta.encoder.layer.9.crossattention.self.query.weight', 'roberta.encoder.layer.9.crossattention.self.value.bias', 'roberta.encoder.layer.9.crossattention.self.value.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The following encoder weights were not tied to the decoder ['roberta/pooler']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD2jv3GkyjR-"
      },
      "source": [
        "# set special tokens\n",
        "roberta_shared.config.decoder_start_token_id = tokenizer.bos_token_id\n",
        "roberta_shared.config.eos_token_id = tokenizer.eos_token_id\n",
        "\n",
        "# sensible parameters for beam search\n",
        "# set decoding params\n",
        "roberta_shared.config.max_length = 64\n",
        "roberta_shared.config.early_stopping = True\n",
        "roberta_shared.config.no_repeat_ngram_size = 3\n",
        "roberta_shared.config.length_penalty = 2.0\n",
        "roberta_shared.config.num_beams = 4\n",
        "roberta_shared.config.vocab_size = roberta_shared.config.encoder.vocab_size"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u98CLZiTkgzv"
      },
      "source": [
        "### **Fine-Tuning Warm-Started Encoder-Decoder Models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gYzA-w96wCt"
      },
      "source": [
        "The `Seq2SeqTrainer` that can be found under [examples/seq2seq/seq2seq_trainer.py](https://github.com/huggingface/transformers/blob/master/examples/seq2seq/seq2seq_trainer.py) will be used to fine-tune a warm-started encoder-decoder model.\n",
        "\n",
        "Let's download the `Seq2SeqTrainer` code and import the module along with `TrainingArguments`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyiwaF0noA5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f341e94-563f-4732-db35-d2063bb555a5"
      },
      "source": [
        "!rm seq2seq_trainer.py\n",
        "!wget https://github.com/huggingface/transformers/blob/main/examples/legacy/seq2seq/seq2seq_trainer.py\n",
        "\n",
        "!pip install git-python==1.0.3\n",
        "!pip install rouge_score"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-29 10:30:31--  https://github.com/huggingface/transformers/blob/main/examples/legacy/seq2seq/seq2seq_trainer.py\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘seq2seq_trainer.py’\n",
            "\n",
            "seq2seq_trainer.py      [  <=>               ] 216.76K   924KB/s    in 0.2s    \n",
            "\n",
            "2025-08-29 10:30:32 (924 KB/s) - ‘seq2seq_trainer.py’ saved [221958]\n",
            "\n",
            "Requirement already satisfied: git-python==1.0.3 in /usr/local/lib/python3.12/dist-packages (1.0.3)\n",
            "Requirement already satisfied: gitpython in /usr/local/lib/python3.12/dist-packages (from git-python==1.0.3) (3.1.45)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython->git-python==1.0.3) (4.0.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython->git-python==1.0.3) (5.0.2)\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.12/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rouge_score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y sacrebleu mecab-python3\n",
        "!pip install \"sacrebleu>=2.4,<3\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDZ7zF7qQny6",
        "outputId": "b7444657-616c-4684-bc89-eadda813e083"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping sacrebleu as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping mecab-python3 as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting sacrebleu<3,>=2.4\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu<3,>=2.4)\n",
            "  Using cached portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from sacrebleu<3,>=2.4) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.12/dist-packages (from sacrebleu<3,>=2.4) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from sacrebleu<3,>=2.4) (2.0.2)\n",
            "Collecting colorama (from sacrebleu<3,>=2.4)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from sacrebleu<3,>=2.4) (5.4.0)\n",
            "Downloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 portalocker-3.2.0 sacrebleu-2.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O seq2seq_trainer.py \\ https://raw.githubusercontent.com/huggingface/transformers/main/examples/legacy/seq2seq/seq2seq_trainer.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbHR_Z1ZNxJ_",
        "outputId": "41594063-40ff-455e-b0fb-d48218f02c60"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " https://raw.githubusercontent.com/huggingface/transformers/main/examples/legacy/seq2seq/seq2seq_trainer.py: Scheme missing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments, Trainer\n",
        "from transformers import TrainingArguments\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Optional"
      ],
      "metadata": {
        "id": "oxOeTJyXNuaC"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nmQRT3XuHHz"
      },
      "source": [
        "We need to add some additional parameters to make `TrainingArguments` compatible with the `Seq2SeqTrainer`. Let's just copy the `dataclass` arguments as defined in [this file](https://github.com/patrickvonplaten/transformers/blob/make_seq2seq_trainer_self_contained/examples/seq2seq/finetune_trainer.py)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPUAgo7pxH24"
      },
      "source": [
        "Also, we need to define a function to correctly compute the ROUGE score during validation. ROUGE is a much better metric to track during training than only language modeling loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQgzLsU_MJyz"
      },
      "source": [
        "import datasets"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68IHmFYLx09W"
      },
      "source": [
        "# load rouge for validation\n",
        "rouge = datasets.load_metric(\"rouge\")\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels_ids = pred.label_ids\n",
        "    pred_ids = pred.predictions\n",
        "\n",
        "    # all unnecessary tokens are removed\n",
        "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
        "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
        "\n",
        "    rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n",
        "\n",
        "    return {\n",
        "        \"rouge2_precision\": round(rouge_output.precision, 4),\n",
        "        \"rouge2_recall\": round(rouge_output.recall, 4),\n",
        "        \"rouge2_fmeasure\": round(rouge_output.fmeasure, 4),\n",
        "    }"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ik4hZb2yV-b"
      },
      "source": [
        "Cool! Finally, we start training."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U datasets evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 983
        },
        "id": "E3vNvhxJTzNU",
        "outputId": "e2b409b6-a32c-4d1f-9224-3449b3830ae0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (1.0.2)\n",
            "Collecting datasets\n",
            "  Using cached datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.19.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.5.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.34.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.8)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Using cached datasets-4.0.0-py3-none-any.whl (494 kB)\n",
            "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "Installing collected packages: dill, datasets\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.5.1\n",
            "    Uninstalling dill-0.3.5.1:\n",
            "      Successfully uninstalled dill-0.3.5.1\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 1.0.2\n",
            "    Uninstalling datasets-1.0.2:\n",
            "      Successfully uninstalled datasets-1.0.2\n",
            "Successfully installed datasets-4.0.0 dill-0.3.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "datasets",
                  "dill"
                ]
              },
              "id": "8cca0eadaa77454ea78247cd6bd1f37d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "if not hasattr(np, \"object\"):\n",
        "    np.object = object\n"
      ],
      "metadata": {
        "id": "_WMKBK5cY2a1",
        "outputId": "c5dc99bc-f33c-4b87-e103-96a12a7bac98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1078063041.py:2: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(np, \"object\"):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "5l5qX8ZUY_ez"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAaTxUpdzshF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "17ab05b5-1e8c-4478-967e-47ea6c5edde3"
      },
      "source": [
        "# set training arguments - these params are not really tuned, feel free to change\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir= OUTPUT_DIR,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    predict_with_generate=True,\n",
        "    # evaluate_during_training=True,\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    logging_steps=200,  # set to 2000 for full training\n",
        "    save_steps=5000,  # set to 500 for full training\n",
        "    eval_steps=7500,  # set to 7500 for full training\n",
        "    warmup_steps=3000,  # set to 3000 for full training\n",
        "    num_train_epochs=10, #uncomment for full training\n",
        "    overwrite_output_dir=True,\n",
        "    save_total_limit=50,\n",
        "    fp16=True,\n",
        ")\n",
        "\n",
        "# instantiate trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=roberta_shared,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=train_data_batch,\n",
        "    eval_dataset=val_data_batch,\n",
        ")\n",
        "\n",
        "# Train pre-trained model\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2815' max='65890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 2815/65890 16:47 < 6:16:27, 2.79 it/s, Epoch 0.43/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>5.200900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.716300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.053100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.008900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.003500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.002800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.003300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.003000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.002000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.004200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.001300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.000800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.006100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.003300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3555' max='65890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 3555/65890 21:07 < 6:10:42, 2.80 it/s, Epoch 0.54/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>5.200900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.716300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.053100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.008900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.003500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.002800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.003300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.003000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.002000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.004200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.001300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.000800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.006100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.003300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.003400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.000800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2267718364.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Train pre-trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2236\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2237\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2238\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2239\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2240\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2580\u001b[0m                     )\n\u001b[1;32m   2581\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2582\u001b[0;31m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2584\u001b[0m                     if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3843\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"scale_wrt_gas\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3845\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3847\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2728\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2729\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2730\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2731\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_lomo_optimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2732\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlomo_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             )\n\u001b[0;32m--> 647\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    830\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7854KKs6EY4x"
      },
      "source": [
        "!gsutil -m cp -r '/content/training/*' 'gs://kaggle-vbdi-test/training_Data'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwQIEhKOrJpl"
      },
      "source": [
        "### **Evaluation**\n",
        "\n",
        "Awesome, we finished training our dummy model. Let's now evaluated the model on the test data. We make use of the dataset's handy `.map()` function to generate a summary of each sample of the test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOoSrwWarJAC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "0ef7f4e43319429d9277d55c83cb084d",
            "ab543b6ef5b34ed4acb85fd25304ed75",
            "825d4b325e9b45859e808cd6b14fdd42",
            "dd0bdf658c6d4c0cb0a091129ecbebb0",
            "f7c296a0b8a84ee3be45c92edb6aad21",
            "e21d97b40ffa43668b9962c5d771debb",
            "a4898ec38618401396928eee2c4f9926",
            "3598a3c015a64c20be134cf4d2e7fbbe"
          ]
        },
        "outputId": "67b60b74-c47c-4718-82a7-072f85a32c4b"
      },
      "source": [
        "import datasets\n",
        "from transformers import RobertaTokenizer, EncoderDecoderModel, AutoTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\", use_fast=False)\n",
        "\n",
        "model = EncoderDecoderModel.from_pretrained(OUTPUT_DIR + \"/checkpoint-4000\")\n",
        "model.to(\"cuda\")\n",
        "\n",
        "# test_data = datasets.load_dataset(\"xsum\", split=\"test\")\n",
        "\n",
        "batch_size = 16  # change to 64 for full evaluation\n",
        "\n",
        "# map data correctly\n",
        "def generate_summary(batch):\n",
        "    # Tokenizer will automatically set [BOS] <text> [EOS]\n",
        "    inputs = tokenizer(batch[\"original\"], padding=\"max_length\", truncation=True, max_length=256, return_tensors=\"pt\")\n",
        "    input_ids = inputs.input_ids.to(\"cuda\")\n",
        "    attention_mask = inputs.attention_mask.to(\"cuda\")\n",
        "\n",
        "    outputs = model.generate(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    # all special tokens including will be removed\n",
        "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "\n",
        "    batch[\"pred\"] = output_str\n",
        "\n",
        "    return batch\n",
        "\n",
        "results = test_data.map(generate_summary, batched=True, batch_size=batch_size, remove_columns=[\"original\"])\n",
        "\n",
        "pred_str = results[\"pred\"]\n",
        "label_str = results[\"summary\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ef7f4e43319429d9277d55c83cb084d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=22.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHl8NMjEiTb6"
      },
      "source": [
        "rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge1\",\"rouge2\",\"rougeL\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13HUSVh4-CAk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96f5c2c3-439c-41f5-e757-02e9aa568c5a"
      },
      "source": [
        "for key,value in rouge_output.items():\n",
        "  print(key)\n",
        "  print(value.mid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rouge1\n",
            "Score(precision=0.6156883807011324, recall=0.6143045549259318, fmeasure=0.5906751582344583)\n",
            "rouge2\n",
            "Score(precision=0.3081612284527864, recall=0.3055766169704671, fmeasure=0.29421411955015214)\n",
            "rougeL\n",
            "Score(precision=0.4081913955092156, recall=0.405197179436527, fmeasure=0.3907000488647073)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8R5CclwUGuC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b53d98d-8d04-49b5-c55a-d47530564398"
      },
      "source": [
        "i = 154\n",
        "print('Prediction: ',pred_str[i])\n",
        "print('Truth: ',label_str[i])\n",
        "print('Content: ',test_data[i]['original'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction:  Tên trộm đã đột_nhập đền Xã_Tắc ( phường Ka_Long, TP. Móng_Cái ) lấy trộm khoảng 300 triệu đồng từ hòm công_đức.\n",
            "Truth:  Camera tại đền Xã_Tắc ( Quảng_Ninh ) ghi lại hình_ảnh hai thanh_niên cạy cửa đền , dùng thanh sắt và đục phá hỏng 3 chiếc hòm công_đức lấy đi số tiền ước_tính 300 triệu đồng .\n",
            "Content:  Công_an thành_phố Móng_Cái ( Quảng_Ninh ) đang truy_tìm hai nghi phạm trộm tài_sản tại đền Xã_Tắc ở phường Ka_Long . Trước đó , khoảng 2h15 ngày 28/5 , hai thanh_niên đột_nhập đền , cạy cửa , phá hỏng 3 chiếc hòm công_đức lấy đi toàn_bộ tiền bên trong . Tài_sản bị mất ước_chừng 300 triệu đồng , chủ_yếu có mệnh_giá 10.000-50.000 đồng . Hình_ảnh do camera an_ninh ghi lại cho thấy hai nghi phạm tuổi từ 25 đến 30 . Phân_tích các dữ_liệu , cảnh_sát nhận_định , một người cao khoảng 1m65 , miệng rộng , má hóp , dáng gầy , mặc áo_phông ngắn tay màu nâu , đội mũ lưỡi chai màu ghi . Người thứ hai cao khoảng 1m70 , dáng gầy , mặc quần vải màu đen , áo sơmi dài tay tối màu , đội mũ che_kín mặt và đầu . Công_an thành_phố Móng_Cái đề_nghị ai biết thông_tin liên_hệ với Đội cảnh_sát điều_tra về trật_tự xã_hội . Đền Xã_Tắc được xây_dựng khoảng cuối thế_kỷ thứ 13 , nằm ở khu_vực biên_cương của tổ_quốc , bên bờ sông Ka_Long . Đây một trong những di_tích lịch_sử vào loại lâu_đời nhất ở Móng_Cái .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4kLAIQSr5g2",
        "outputId": "b4d745cb-4599-43cf-e8c0-1ec9e5fdba6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test_data[i]['file']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/ViMs/original/Cluster_256/original/1671.txt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D__lCYyZvFhr"
      },
      "source": [
        "rdrsegmenter = VnCoreNLP(\"./vncorenlp/VnCoreNLP-1.1.1.jar\", annotators=\"wseg\", max_heap_size='-Xmx2g')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWa2uIUHzY1R"
      },
      "source": [
        "text = '''\n",
        " Ngày 4/2, lãnh đạo thị xã Hoàng Mai (Nghệ An) cho biết, cơ quan chức năng thị xã vừa phối hợp với đơn vị chức năng tỉnh cách ly, lấy mẫu xét nghiệm cho 1 nam sinh viên trường Đại học FPT có biểu hiện ho sốt sau khi đi từ Hà Nội về nhà.\n",
        "\n",
        "Trước đó vào ngày 31/1 nam sinh C.T.Ph. (20 tuổi, trú TX. Hoàng Mai, Nghệ An; Sinh viên trường Đại học FPT cơ sở Mỹ Đình) cùng 1 người bạn đi xe máy từ Hà Nội về quê nhà.\n",
        "\n",
        "Lúc 22h ngày 31/1 nam sinh này về đến quê nhà nhưng không khai báo y tế. Từ ngày 1-3/2, nam sinh Ph. có đi một số nơi trên địa bàn thị xã và tiếp xúc với khoảng 12 người.\n",
        "\n",
        "\n",
        "Khoảng 20h ngày 3/2, nam sinh này có dấu hiệu sốt 39 độ, đau đầu, đau rát họng, đau mỏi cơ, khó thở nhẹ. Nam sinh này sau đó được đưa vào Bệnh viện Phong da liễu (TX. Hoàng Mai) để khám và cách ly y tế.\n",
        "\n",
        "Nhận được tin báo, Trung tâm Kiểm soát bệnh tật tỉnh Nghệ An đã trực tiếp ra lấy mẫu bệnh phẩm để xét nghiệm Covid-19. Dự kiến trong chiều cùng ngày sẽ có kết quả.\n",
        "\n",
        "Hiện cơ quan chức năng đang rà soát những người tiếp xúc gần với nam sinh Ph. để có phương án theo dõi, cách ly và lấy mẫu xét nghiệm.\n",
        "\n",
        "Trước đó vào đêm 31/1, một chuyến xe khách chở 22 người từ Hà Nội về Nghệ An trong đó có nhiều sinh viên Đại học FPT đi về tại phường Lê Lợi, TP. Vinh (Nghệ An). Cơ quan chức năng sau đó đã đưa 1 trường hợp F1 trên xe khách này đi cách ly tại Trung tâm Y tế huyện Nam Đàn. Riêng những trường hợp còn lại được theo dõi tại nhà.\n",
        "\n",
        "Sau khi cách ly, các trường hợp này đã được lấy mẫu xét nghiệm và cho kết quả âm tính với Covid-19.\n",
        " '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUXmH90UznVP",
        "outputId": "7f910890-57f6-4198-f0d0-6c9d5a13cac5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "text = rdrsegmenter.tokenize(text)\n",
        "text = ' '.join([' '.join(x) for x in text])\n",
        "text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Ngày 4/2 , lãnh_đạo thị_xã Hoàng_Mai ( Nghệ_An ) cho biết , cơ_quan_chức_năng thị_xã vừa phối_hợp với đơn_vị chức_năng tỉnh cách_ly , lấy mẫu xét_nghiệm cho 1 nam sinh_viên trường Đại_học FPT có biểu_hiện ho sốt sau khi đi từ Hà_Nội về nhà . Trước đó vào ngày 31/1 nam_sinh C.T.Ph. ( 20 tuổi , trú TX . Hoàng_Mai , Nghệ_An ; Sinh_viên trường Đại_học FPT cơ_sở Mỹ_Đình ) cùng 1 người bạn đi xe_máy từ Hà_Nội về quê nhà . Lúc 22h ngày 31/1 nam_sinh này về đến quê nhà nhưng không khai_báo y_tế . Từ ngày 1-3/2 , nam_sinh Ph . có đi một_số nơi trên địa_bàn thị_xã và tiếp_xúc với khoảng 12 người . Khoảng 20h ngày 3/2 , nam_sinh này có dấu_hiệu sốt 39 độ , đau_đầu , đau rát họng , đau mỏi cơ , khó thở nhẹ . Nam_sinh này sau đó được đưa vào Bệnh_viện Phong da_liễu ( TX . Hoàng_Mai ) để khám và cách_ly y_tế . Nhận được tin báo , Trung_tâm Kiểm_soát bệnh_tật tỉnh Nghệ_An đã trực_tiếp ra lấy mẫu bệnh_phẩm để xét_nghiệm Covid-19 . Dự_kiến trong chiều cùng ngày sẽ có kết_quả . Hiện cơ_quan_chức_năng đang rà_soát những người tiếp_xúc gần với nam_sinh Ph . để có phương_án theo_dõi , cách_ly và lấy mẫu xét_nghiệm . Trước đó vào đêm 31/1 , một chuyến xe_khách chở 22 người từ Hà_Nội về Nghệ_An trong đó có nhiều sinh_viên Đại_học FPT đi về tại phường Lê_Lợi , TP. Vinh ( Nghệ_An ) . Cơ_quan_chức_năng sau đó đã đưa 1 trường_hợp F1 trên xe_khách này đi cách_ly tại Trung_tâm Y_tế huyện Nam_Đàn . Riêng những trường_hợp còn lại được theo_dõi tại nhà . Sau khi cách_ly , các trường_hợp này đã được lấy mẫu xét_nghiệm và cho kết_quả âm_tính với Covid-19 .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCQ5zA96zuzu",
        "outputId": "3f12d605-3f82-451b-ee4d-349ebe54edec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "inputs = tokenizer(text, padding=\"max_length\", truncation=True, max_length=256, return_tensors=\"pt\")\n",
        "input_ids = inputs.input_ids.to(\"cuda\")\n",
        "attention_mask = inputs.attention_mask.to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "# all special tokens including will be removed\n",
        "output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "output_str"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Trong người bạn gái của một cán_bộ Công_an tỉnh Nghệ_An cho biết, đơn_vị đang khẩn_trương điều_tra, xác_minh nguyên_nhân khiến một nam thanh_niên tử_vong.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H06_kgjD3ftO"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db7b45c1",
        "outputId": "301e3c9d-1982-437c-f8c8-1e5ab43c1b7d"
      },
      "source": [
        "!pip install --upgrade dill"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (0.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5QnA2clyJANn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}